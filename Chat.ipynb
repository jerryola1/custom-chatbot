{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b41fa75d-244c-45ff-8f70-ff0f6c4bc7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# Install the requests module\n",
    "# !pip install requests\n",
    "\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c182ddda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7e5f1ca8-40d3-4b6b-82a1-07b135873ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "# device selection logic\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"Using GPU\")\n",
    "    device = '/GPU:0'\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = '/CPU:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26540604-6ac7-433b-8a65-ac52bf8ecc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "# os.environ[\"HUGGINGFACEHUB_API_TEKEN\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccaf2eef-cc42-4e7e-92d7-fc84c1e609b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sitemap_urls(sitemap_url):\n",
    "    response = requests.get(sitemap_url)\n",
    "    sitemap = response.content\n",
    "    root = ET.fromstring(sitemap)\n",
    "    urls = [url.text for url in root.findall('.//{http://www.sitemaps.org/schemas/sitemap/0.9}loc')]\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8402b8e-a021-47bc-99e4-3a25292bd21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get URLs from sitemap\n",
    "sitemap_url = 'https://www.hull.ac.uk/sitemap.xml'\n",
    "urls = get_sitemap_urls(sitemap_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5467a19-41fb-46c1-90f8-e32cd40bfb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "while tf.device(device):\n",
    "    loaders = UnstructuredURLLoader(urls=urls)\n",
    "    data = loaders.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7db0b0-e726-44f2-8a95-5ca0b9f4b3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5340b0e6-8ad2-4a65-9305-486d356d44cd",
   "metadata": {},
   "source": [
    "### save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6496e8c9-9c0e-4714-a14b-c52c3471e616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_str = '\\n'.join(doc.page_content for doc in data)\n",
    "\n",
    "# # Save the string to a text file\n",
    "# with open('data.txt', 'w') as file:\n",
    "#     file.write(data_str)\n",
    "\n",
    "import json\n",
    "# Prepare data for saving\n",
    "data_to_save = [{'page_content': doc.page_content, 'metadata': doc.metadata} for doc in data]\n",
    "\n",
    "# Save data to a JSON file\n",
    "with open('data.json', 'w') as file:\n",
    "    json.dump(data_to_save, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc28cb17-4d71-47a6-b5b2-f909954b79aa",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe18c3f6-5e05-455d-97ff-0e83eb6e15ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from the JSON file\n",
    "with open('data.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf06681-83af-4a92-a92e-9e38e5b45f10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ee15a03-76a4-420d-b000-b45a74602a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# Define the Document class\n",
    "class Document:\n",
    "    def __init__(self, page_content, metadata):\n",
    "        self.page_content = page_content\n",
    "        self.metadata = metadata\n",
    "\n",
    "# Initialize the text splitter\n",
    "text_splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=10000, chunk_overlap=2000)\n",
    "\n",
    "with open('data.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Convert dictionaries to Document objects\n",
    "docs = [Document(doc['page_content'], doc['metadata']) for doc in data]\n",
    "\n",
    "# Use the text splitter to split documents\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "# Load embeddings\n",
    "# embeddings_array = np.load('embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66beecf-9b1b-41ea-aa66-064c82a62c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8526972-317b-4d5e-97db-c2b0334bb089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='500\\nThe page you were visiting has generated an error. You could go straight to our home page?', metadata={'source': 'https://www.hull.ac.uk/work-with-us/research/groups/positron-emission-tomography-research-centre.aspx'})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs[1660]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05c787a2-a5c2-4e0f-86a3-0e6f5f000025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import faiss\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "163f4f22-e7e5-4a95-98c5-8a5bb50f6f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = OpenAIEmbeddings(model=\"text-embeddings-ada-002\", \n",
    "#                              openai_api_type=None,\n",
    "#                               chunk_size=1000,\n",
    "#                               max_retries=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41e3af5a-c869-454b-92ae-873839040a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# print(os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0928e0b-d143-4aa8-9e55-037f5457eaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorStore_openAI = FAISS.from_documents(docs, embeddings)\n",
    "# with open(\"faiss_store_openai.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(vectorStore_openAI, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77061fe-61cc-4586-9a68-a9410949d3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"faiss_store_openai.pkl\", \"rb\") as f:\n",
    "#     VectorStore = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "25f72bd0-26be-458b-94e6-641793c64527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained model tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "with tf.device(device):\n",
    "    # Function to handle texts longer than 512 tokens\n",
    "    def generate_embeddings(text):\n",
    "        stride = 128  # Overlap size\n",
    "        max_len = 512  # Max token length for BERT\n",
    "        tokens = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_len)\n",
    "        token_chunks = [tokens[i:i+max_len] for i in range(0, len(tokens), max_len-stride)]\n",
    "        \n",
    "        # Initialize a list to hold embeddings of each chunk\n",
    "        chunk_embeddings = []\n",
    "        \n",
    "        for chunk in token_chunks:\n",
    "            # Generate embeddings for each chunk\n",
    "            with torch.no_grad():  # Disable gradient calculation for inference\n",
    "                outputs = model(**chunk)\n",
    "                chunk_embeddings.append(outputs.last_hidden_state.mean(1))\n",
    "        \n",
    "        # Combine chunk embeddings by averaging\n",
    "        embeddings = torch.mean(torch.stack(chunk_embeddings), dim=0)\n",
    "        return embeddings\n",
    "    \n",
    "    # Generate embeddings for each document\n",
    "    embeddings = [generate_embeddings(doc.page_content) for doc in split_docs]\n",
    "    \n",
    "    # Convert embeddings to numpy array and save to disk\n",
    "    embeddings_array = torch.stack(embeddings).numpy()\n",
    "    np.save('bert_embeddings.npy', embeddings_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2355e89-d4dd-4751-b1b2-00994e824b16",
   "metadata": {},
   "source": [
    "### Save Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a2266dfe-b223-4ea4-a2dc-12c0e59f8f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metadata to a JSON file\n",
    "metadata_list = [doc.metadata for doc in split_docs]\n",
    "with open('metadata.json', 'w') as f:\n",
    "    json.dump(metadata_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef3c2c9-7707-48df-af96-982fcf0a968c",
   "metadata": {},
   "source": [
    "### Loading Embeddings and Metadata from Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "580f68ef-1b96-4cef-ab95-940d0d117717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings from the NumPy binary file\n",
    "loaded_embeddings = np.load('bert_embeddings.npy')\n",
    "\n",
    "# Load metadata from the JSON file\n",
    "with open('metadata.json', 'r') as f:\n",
    "    loaded_metadata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de59a7f3-69df-4617-aa43-0eaab70da8a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df0eb985-e06a-47e0-b21c-b69b67e81e09",
   "metadata": {},
   "source": [
    "### Convert embeddings to 2D numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "50f3369d-9434-47ff-b62f-7cc6d54890d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b05e4bea-4c39-48b6-bc8d-bc7a026369e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3460, 1, 768)\n"
     ]
    }
   ],
   "source": [
    "print(loaded_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9b3813fa-fc89-4427-b393-ad86459a3fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "# Reshape loaded_embeddings from (3460, 1, 768) to (3460, 768)\n",
    "loaded_embeddings = loaded_embeddings.reshape(loaded_embeddings.shape[0], loaded_embeddings.shape[2])\n",
    "\n",
    "# Ensure the embeddings are of type float32\n",
    "if loaded_embeddings.dtype != np.float32:\n",
    "    loaded_embeddings = loaded_embeddings.astype(np.float32)\n",
    "\n",
    "# Initialize the FAISS index\n",
    "dimension = loaded_embeddings.shape[1]  # Dimension of the embeddings\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 distance for similarity\n",
    "\n",
    "# Add embeddings to the index\n",
    "index.add(loaded_embeddings)  # Now the index is ready for searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3f8ff2b0-8161-4b82-bb2c-b80ea48dc73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert user query to embedding\n",
    "query_text = \"How do i apply for phd?\"  # Replace with the actual user query\n",
    "query_embedding = generate_embeddings(query_text)\n",
    "\n",
    "# Use FAISS to find top k nearest document embeddings to the query embedding\n",
    "k = 5  # Number of nearest neighbors\n",
    "D, I = index.search(query_embedding, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4068d42-f0f3-450b-a6b0-c763e1f83d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5a3536be-4a23-4f96-8734-2336a0ad7027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: No response generated\n",
      "Source: https://www.hull.ac.uk/faculties/subjects/features/computer-science-industry-placements.aspx\n",
      "Answer: No response generated\n",
      "Source: https://www.hull.ac.uk/work-with-us/more/media-centre/news/2022/studying-in-the-uk-as-an-international-student.aspx\n",
      "Answer: No response generated\n",
      "Source: https://www.hull.ac.uk/work-with-us/more/media-centre/news/2021/the-time-had-come-for-me-to-get-the-education-i-wanted.aspx\n",
      "Answer: No response generated\n",
      "Source: https://www.hull.ac.uk/faculties/subjects/features/graduate-q-and-a-grace-marner-bsc-biology.aspx\n",
      "Answer: No response generated\n",
      "Source: https://www.hull.ac.uk/clearing/student-finance.aspx\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(max_tokens=50)\n",
    "\n",
    "for idx in I[0]:\n",
    "    document_content = split_docs[idx].page_content  # Retrieve the content of the relevant document\n",
    "    source_url = loaded_metadata[idx]['source']  # Retrieve the source URL of the relevant document\n",
    "    \n",
    "    # Construct the conversation\n",
    "    response = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": query_text},\n",
    "        {\"role\": \"assistant\", \"content\": document_content},\n",
    "        {\"role\": \"user\", \"content\": \"Can you give me more information about this?\"}\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    # Extract the generated answer from the response\n",
    "    # Check if 'choices' is in the response and extract the content safely\n",
    "    if 'choices' in response and response['choices']:\n",
    "        answer = response['choices'][0]['message']['content']\n",
    "    else:\n",
    "        answer = 'No response generated'\n",
    "\n",
    "    # Print or process the answer and the source URL\n",
    "    print(\"Answer:\", answer)\n",
    "    print(\"Source:\", source_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "93149742-d28f-4a3b-954b-5cc439a5687d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8mgjlsCKC6YQsleYoEQ1Joax2baoa', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Of course! Applying for a PhD (Doctor of Philosophy) typically involves several steps. Here is a general overview:\\n\\n1. Research Your Field: Start by exploring different research areas and topics within your field of interest. Look for potential supervisors or research groups that align with your research interests.\\n\\n2. Contact Potential Supervisors: Reach out to professors or researchers who specialize in your area of interest. Introduce yourself, explain your research interests, and inquire about potential PhD opportunities in their research group. Building relationships with potential supervisors is crucial, as they can guide you through the application process.\\n\\n3. Prepare Your Application Materials: Once you have found a potential supervisor and research topic, you will need to prepare your application materials, which typically include:\\n\\n   - Research Proposal: Write a detailed research proposal outlining your research objectives, methodology, and potential impact.\\n   - Academic Transcripts: Provide official transcripts from your previous educational institutions, including both undergraduate and postgraduate degrees.\\n   - Curriculum Vitae (CV): Prepare a comprehensive CV highlighting your academic achievements, research experience, publications, and any relevant work experience.\\n   - Letters of Recommendation: Request letters of recommendation from academic advisors, professors, or employers who can speak to your academic abilities and potential for research. Aim for at least three strong references.\\n   - Language Proficiency: If English is not your native language, you may need to demonstrate English language proficiency through tests like IELTS or TOEFL.\\n   - Entrance Examinations: Some universities or programs may require you to take entrance examinations specific to your field of study. Check the requirements of your chosen program.\\n\\n4. Application Submission: Submit your application materials through the university's online application portal or any other designated method. Make sure to follow the application deadlines and instructions provided by the university or department.\\n\\n5. Funding and Scholarships: Explore funding options such as scholarships, grants, or research assistantships. PhD programs often provide financial support to students through various sources. Investigate external scholarships or research grants as well.\\n\\n6. Selection and Interview: If your application is shortlisted, you may be invited for an interview or further assessment. This can be a formal interview, research presentation, or both. Prepare well and showcase your research potential and enthusiasm during the interview.\\n\\n7. Acceptance and Enrollment: If you are offered a place in a PhD program, carefully review the offer letter, including any financial support, stipulations, and enrollment requirements. Accept the offer and proceed with the enrollment process as instructed by the university.\\n\\nIt is important to note that the application process may vary depending on the country, university, and specific department requirements. Make sure to thoroughly research the application process for each institution you are considering.\", role='assistant', function_call=None, tool_calls=None))], created=1706614717, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=543, prompt_tokens=2162, total_tokens=2705))\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fde5591e-ed11-4f0c-b165-6399d536c2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: No response generated\n",
      "Source: https://www.hull.ac.uk/clearing/student-finance.aspx\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer:\", answer)\n",
    "print(\"Source:\", source_url)  # This should be the URL of the document that was used to generate the context for the answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd743bc-44f2-42b6-be78-b21fb8fdc3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
